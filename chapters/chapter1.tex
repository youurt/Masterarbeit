\chapter{Einleitung}\label{ch1}

\section{Motivation}

Das Aufkommen von Online-Nachrichtenagenturen und die Explosion der Anzahl der Benutzer, die Nachrichten mit diesem Medium konsumieren, haben dazu geführt, dass mehrere Webseiten miteinander konkurrieren, um die Aufmerksamkeit der Benutzer zu erregen. Dies hat dazu geführt, dass Verkaufsstellen kreative Wege geschaffen haben, um Leser auf ihre Website zu locken. Eine der am häufigsten verwendeten Techniken ist die Verwendung von Clickbait-Überschriften. Diese Überschriften wurden speziell dafür entwickelt, um das Interesse des Lesers an dem zu wecken, was versprochen wird. Wenn auf den Artikel geklickt wird jedoch, liefert dieser Artikel normalerweise nicht den Inhalt, den der Leser ursprünglich gesucht hat. 

Durch Deep Learning können Daten in verschiedener Art klassifiziert werden. Es ist üblich für Textklassifikation RNNs oder LSTMs zu verwenden. Diese Arbeit versucht mit einem 1-Dimensionalen CNN, eine binäre Textklassifikation durchzuführen. Das Model soll nachher so umgewandelt werden, dass es als Webapplikation erstellt werden kann. Das Ziel ist es mittel die Applikation ohne einen Server, cleintseitig zu implementieren.

Um mit Deep Learning Klassifikationsprobleme zu lösen, benötigt es an Daten. Es gibt für deutsche Clickbaits keinen Datensatz, sodass dieser selbstständig erstellt wird. Dieser Datensatz soll dann zum Tranieren verwendet werden. 


\section{Forschungsfragen}
Die Arbeit soll folgende Fragen beantworten:
\begin{enumerate}
    \item Wie kann ein Datensatz für deutsche Clickbaits erstellt werden?
    \item Können CNNs dafür eingesetzt werden, um Clickbaits zu klassifizieren?
    \item Wie können Deep Learning Modelle in eine Web-Anwendung eingebettet werden?
\end{enumerate}

\section{Aufbau der Arbeit}
Der Kapitel~\ref{ch2} wird das \textit{Deep Learning} theoretisch erläutert. Hier wird das Perzeptron dargestellt welches ein Algorithmus ist, das seinen Ursprung aus der Natur hat. Es werden mehrere \enquote{Neuronen} miteinander verbunden und bilden als Ganzes ein System, welches dafür genutzt werden kann, um bestimmte Probleme zu lösen. In diesem Kapitel werden Funktionen wie Aktivierungsfunktionen mathematisch beschrieben. Diese Funktionen werden in späteren Kapiteln angewendet, sodass hier relativ wenige Beispiele vorhanden sind. In diesem Kapitel soll auch gezeigt werden, wie ein Deep Learning Modell lernt. Hier werden die Algorithmen Gradientenabstiegsverfahren und das Backpropogation erläutert. Im Deep Learning können Feinheiten über den Erfolg eines Modells entscheiden. Der Auswahl geeigneter Parameter ist dabei besonders wichtig. Aus diesem Grund werden wichtige Parameter wie \enquote{Lernrate} und Begriffe wie \enquote{Über-} und \enquote{Unteranpassung} als Optimierungsalgorithmen vorgestellt. Zusätzlich werden Maßnahmen diskutiert, die eine Auswirkung auf \enquote{Über-} und \enquote{Unteranpassung} haben können, Regularisierung. Neben Aktivierungsfunktionen und Optimierungsalgorithmen gibt es die Verlustfunktion im Deep Learning. Ein Netzwerk muss also wissen wie falsch es liegt. Deep Learning bietet verschiedene Möglichkeiten, um Netzwerke zu modellieren. Ein bekanntes Verfahren ist das sogenannte \enquote{CNN}, welches ein \enquote{Faltungsnetzwerk} ist und in diesem Kapitel vorgestellt wird.

Im Kapitel~\ref{ch3} geht es um die Verarbeitung der natürlichen Sprache. Es werden zunächst die standardisierten Verfahren wie Reguläre Ausdrücke und wie durch reguläre Ausdrücke ein Text in seine einzelnen Elemente (Tokens) umgewandelt werden kann. Dieses Verfahren wird in den späteren Kapiteln häufig gebraucht. Neben dem Verfahren der Tokenisierung, gibt es andere Verfahren im NLP wie, das Tagging der Wörter in seine grammatikalischen Einheiten. Eine Frage die beantwortet werden muss ist, wie Computer die natürliche Sprache lernen. Hier wird zunächst dargestellt, dass ein Computer wesentlich nur Zahlen versteht und eine Umwandlung von Wörtern in Zahlen gelingen muss. Sicherlich gibt es dafür mehrere Verfahren, hier wird die Methode der \enquote{Worteinbettungen} vorgestellt. Kapitel~\ref{ch3} wird damit abgeschlossen, indem eine Verbindung mit Kapitel~\ref{ch1} hergestellt wird. CNN werden häufig für Bilddateien verwendet. Hier wird gezeigt, wie CNNs auch bei der Textverarbeitung angewendet werden können.

Gemeinsam mit Kapitel~\ref{ch2} und Kapitel~\ref{ch3} wird der theoretische Teil der Arbeit abgeschlossen und Kapitel~\ref{ch4} geht es mehr um die Literatur. Um Clickbaits zu klassifizieren ist eine Definition von Clickbaits auszuführen. Dieses ist eine Herausforderung, denn Clickbaits haben eine subjektive Natur und können nur sehr schwer verallgemeinert werden. es gibt jedoch einige \enquote{Muster} die aus mehreren Arbeiten zu entnehmen sind, die sich mit diesem Thema beschäftigt haben. Es soll in diesem Kapitel auch erforscht werden, welche Ansätze es gibt, in Bezug auf \enquote{Klassifizierung von Clickbaits}. Hier wird gezeigt, wie verwandte Arbeiten das Problem gelöst haben und wichtige Erkenntnisse für den weiteren Verlauf der Arbeit herausgezogen.


% TODO


Der Kern der Arbeit befindet sich in Kapitel~\ref{ch5}. Hier wird zunächst ein Konzept vorgestellt, mit dem Ziel der Entwicklung eines Deep Learning Modells. Es gibt dabei grob 3 Etappen, erstens das Erstellen des Datensatzes, zweitens die Entwicklung eines Modells und drittens die Einbettung des Modells in eine Web-Anwendung. Mittels Web-Scraping werden die Daten aus dem Internet geladen und analysiert. Die Erkenntnisse aus Kapitel~\ref{ch3} und Kapitel~\ref{ch4} dienen dabei als Hilfe und werden sowohl bei der Erstellung des Datensatzes als auch beim Labeln der Daten verwendet. Statt die Daten händisch zu labeln werden bestimmte Muster dafür verwendet, um den Datensatz zu generieren. Somit entsteht ein deutscher Datensatz mit 20.000 Elementen, welches zum trainieren eines Deep Learning Modells verwendet werden kann. In diesem Kapitel wird die Technologie von TensorFlow.js vorgestellt, welches das clientseitige Deep Learning erst möglich gemacht hat. Durch Worteinbettungen und einer Faltungsschicht, entsteht ein relativ einfaches und kleines Modell. Das Modell wird hier evaluiert und auf neue Beispiele getestet. Im letzten Teil des Kapitels geht es darum, eine Web-Anwendung auf Basis eines Deep Learning Modells zu implementieren. Hier wird die herkömmliche Methode der \enquote{serverseitigen} Anwendung vorgestellt und zum Kontrast die in dieser Arbeit vorgeschlagene \enquote{clientseitige} Anwendung mit TensorFlow.js. Eine tiefe Beschreibung bei der Anwendung des \enquote{clientseitigen Deep Learnings} wird damit erreicht, indem die Web-Anwendung mittels einer UI umgesetzt wird.